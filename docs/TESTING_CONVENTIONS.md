В документе описаны договорённости по тестированию в проекте HomePlanner. Язык документа — русский. Основной упор сделан на автоматические тесты клиентских приложений и веб-интерфейса.

## 1. Цели и принципы
- Обеспечить воспроизводимое, автоматизируемое и прозрачное тестирование для всех компонентов системы.
- Минимизировать регрессии за счёт раннего обнаружения дефектов.
- Соблюдать единые стандарты написания и запуска тестов независимо от платформы.
- Все автоматические тесты должны быть самодостаточными, изолированными и детерминированными.

## 2. Общие требования
- Фреймворк для Python-компонентов — `pytest`. Модуль `unittest` не использовать.
- Все тесты размещаются в каталоге `./tests`, сохраняя зеркальную структуру.
- Обязательна аннотация типов и наличие docstring для каждого тестового модуля, класса и функции.
- Тестовые данные и фикстуры должны быть минимальными и описательными. Общие фикстуры выносить в `conftest.py`.
- Корневой `conftest.py` размещается в каталоге `tests/` и содержит фикстуры/фабрики, используемые несколькими модулями; в подпакетах допускаются дополнительные `conftest.py` для доменных сценариев.
- Для мокирования использовать `pytest-mock` (`MockerFixture`) или стандартные средства `pytest`. Глобальные моки ограничивать сроком жизни теста.
- Локальные настройки и секреты не хранить в тестах. Использовать отдельный конфиг файл.
- Общие фабрики данных размещаются в `tests/factories` (или соседних доменных подпапках) и импортируются в тесты через `conftest.py`, чтобы избежать дублирования.
- Повторно используемые хелперы (API-пути, нормализация времени, запуск клиентов) выносить в отдельные библиотеки (`tests/utils.py`, `tests/factories/`) и подключать через импорт вместо дублирования кода.
- Логи тестов должны быть информативными (см. `LogCaptureFixture`), но не зашумлять вывод CI. Дефолтный уровень логирования для локальных и CI-прогонов — `WARNING`; снижение уровня оформляется в тесте явно. Рекомендуемый формат сообщения — `<module>::<scenario>::<context>`.
- Локальные и CI-прогоны выполняются через `uv run`: для backend `uv run pytest`, для фронтенда `uv run npm run test`, для Playwright — `uv run npx playwright test`. Последовательность локального запуска python-тестов фиксируем отдельно:
  1. `uv sync` — установка и актуализация зависимостей.
  2. `uv run pytest --maxfail=1 --disable-warnings` — базовый прогон.
  3. `uv run pytest --cov=src --cov-report=term-missing` — проверка покрытия перед публикацией.
- Те же команды закреплены в GitHub Actions `.github/workflows/ci-python-tests.yml`, `.github/workflows/ci-frontend-tests.yml` и `.github/workflows/ci-android.yml`. При обновлении workflow необходимо синхронизировать документ.
- Общие правила расположения артефактов и документов описаны в `docs/ARTIFACTS_LAYOUT.md`; при добавлении новых тестовых пакетов ссылаться на соответствующие разделы.

## 3. Автоматические тесты клиентских приложений (Android)
- **Инструментарий**: Kotlin + JUnit5/AndroidX Test для модульных и инструментальных тестов. Для сквозных сценариев — Espresso или UI Automator.
- **Структура**:
  - Модульные тесты Kotlin находятся в `android/app/src/test/java`.
  - Инструментальные тесты — в `android/app/src/androidTest/java`.
- **Соглашения**:
  - Именование классов тестов: `<ClassName>Test.kt` или `<FeatureName>Spec.kt`.
  - Каждый тест описывает ожидаемое поведение (`fun someCondition_expectedResult()`).
  - Использовать `MockK` или встроенные фреймворки для изоляции зависимостей.
  - При работе с базой данных и сетевыми слоями применять фейковые реализации или эмуляторы.
  - Для UI-тестов гарантировать стабильные идентификаторы `View` (resource-id/contentDescription).
- **Запуск**: описать команды в `docs/DEVELOPMENT.md` и поддерживать Gradle-задачи (`./gradlew test`, `./gradlew connectedDebugAndroidTest`). Минимальный smoke-набор приведён в таблице «Smoke-наборы Android».
- **Отчётность**: хранить артефакты (JUnit XML, скриншоты) в `android/app/build/reports`. CI вытягивает их после прогона.

### 3.1 Smoke-наборы Android

| Сценарий | Описание | Тип теста |
| --- | --- | --- |
| `Создание задачи` | Создать задачу с напоминанием и убедиться, что приходит уведомление в установленный слот | Инструментальный |
| `Синхронизация и редактирование` | Активировать синхронизацию, изменить параметры задачи и подтвердить обновление статуса | Интеграционный |
| `Настройки напоминаний` | Переключить напоминания в настройках приложения и проверить сохранение состояния | UI/E2E |

## 4. Автоматические тесты веб-клиента
- **Стек**: `vitest` для модульных/юнит-тестов, `playwright` или `cypress` для end-to-end. Предпочтительно `playwright` для единообразия и интеграции с CI.
- **Структура**:
  - Юнит-тесты — `frontend/tests/unit`. Именование файлов: `<module>.spec.js` или `.ts` (при миграции на TypeScript).
  - Интеграционные/компонентные тесты — `frontend/tests/integration`.
  - E2E-скрипты — `frontend/tests/e2e`.
- **Соглашения**:
  - Использовать тестовые util-функции (`frontend/utils`) для подготовки данных.
  - Не обращаться напрямую к реальному backend; использовать мок-сервер (MSW) или Playwright fixtures.
  - Прежде чем фиксировать селекторы, обеспечивать устойчивость: data-testid, aria-label, роль.
  - Покрывать не только happy-path, но и негативные сценарии (ошибки сети, пустые состояния).
- **Запуск**:
  - Юнит: `npm run test` (или аналогичная команда через `uv` при конвертации).
  - E2E: `npx playwright test` с настройкой CI-профиля (`playwright.config.ts`). Обязательные сценарии сведены в таблицу «Smoke-наборы веб-клиента» и выполняются на каждый merge request.
- **Отчётность**: сохранять отчёты в `frontend/tests/reports`. CI публикует HTML-репорты и прикладывает скриншоты/видео.

## 5. Интеграция с CI/CD

### 4.1 Smoke-наборы веб-клиента

| Сценарий | Описание | Тип теста |
| --- | --- | --- |
| `Авторизация` | Выполнить вход под тестовым пользователем и проверить редирект на список задач | E2E |
| `Создание задачи` | Создать задачу и убедиться, что она отображается в списке с корректным расписанием | E2E |
| `Редактирование расписания` | Изменить расписание задачи и проверить обновление календаря/виджета | Интеграционный |
| `Удаление задачи` | Удалить задачу и проверить корректное отображение пустого состояния | E2E |
- Все тестовые цепочки должны запускаться в CI при каждом push/PR: backend pytest, Android юнит-тесты, веб-юнит и E2E (в nightly или по тегу).
- Невыеявленные флаки должны помечаться и отслеживаться отдельно. Флаки разрешается временно пропускать только по решению владельца проекта.
- Метрики покрытия (coverage) публикуются в job-артефактах: HTML-отчёт помещается в артефакт `coverage-report`, XML (`coverage.xml`) — в `coverage-summary` для интеграции с Codecov. Для python-домена также выгружается `coverage.lcov` в артефакт `coverage-lcov` и загружается в Codecov. Порог покрытия: не ниже 80% для критичных модулей.
- Для тяжёлых E2E допускается nightly-запуск, но smoke-набор (минимум 3 ключевых сценария) должен выполняться на каждый merge request.

## 6. Документация и поддержка
- Любые новые тестовые сценарии сопровождаются записью в `CHANGELOG_HISTORY.md` при значимых изменениях.
- Руководство по локальному запуску тестов обновляется в `docs/DEVELOPMENT.md`.
- Ответственный за тестирование компонент фиксируется в задаче/issue. Важно поддерживать актуальность контактов.
- В случае обнаружения дефектов тестового окружения — фиксировать в баг-трекере с шагами воспроизведения и ссылкой на failing test.

## 7. Порядок внедрения
- Этап 1: согласовать стек инструментов (Playwright/Cypress, MockK и т. п.) и описать команды запуска.
- Этап 2: покрыть smoke-сценарии веб-клиента и критичные бизнес-операции в Android.
- Этап 3: расширять покрытия, внедрять проверки в CI, отслеживать флаки.
- Этап 4: поддерживать регресс-набор к релизам, формировать отчёты и ретроспективы по качеству.

---
Документ подлежит регулярному пересмотру по мере развития продукта и инфраструктуры тестирования.

