В документе описаны договорённости по тестированию в проекте HomePlanner. Язык документа — русский. Основной упор сделан на автоматические тесты клиентских приложений и веб-интерфейса.

## 1. Цели и принципы
- Обеспечить воспроизводимое, автоматизируемое и прозрачное тестирование для всех компонентов системы.
- Минимизировать регрессии за счёт раннего обнаружения дефектов.
- Соблюдать единые стандарты написания и запуска тестов независимо от платформы.
- Все автоматические тесты должны быть самодостаточными, изолированными и детерминированными.

## 1.1 ВАЖНО ДЛЯ AI-ИНСТРУМЕНТОВ

**ОБЯЗАТЕЛЬНЫЕ ПРАВИЛА при запуске тестов Python:**

1. **НЕ использовать `cd` в командах** — рабочая директория уже установлена в корень проекта автоматически. Все команды выполняются относительно корня проекта без использования `cd`.

2. **ОБЯЗАТЕЛЬНО активировать `.venv` ПЕРЕД запуском тестов** — это должна быть ОТДЕЛЬНАЯ команда:
   ```bash
   source .venv/bin/activate
   ```

3. **Запуск тестов — ОТДЕЛЬНАЯ команда после активации** — после активации `.venv` используется команда `pytest` напрямую (без `.venv/bin/python -m`):
   ```bash
   pytest --maxfail=1 --disable-warnings -v
   ```

**НЕПРАВИЛЬНО (использование `.venv/bin/python -m pytest` без активации):**
```bash
.venv/bin/python -m pytest tests/ -v  # НЕПРАВИЛЬНО!
```

**ПРАВИЛЬНО (отдельная активация + отдельная команда pytest):**
```bash
source .venv/bin/activate  # Отдельная команда 1
pytest tests/ -v          # Отдельная команда 2
```## 2. Общие требования
- **Рабочая директория**: Все команды выполняются из корня проекта. Рабочая директория уже установлена автоматически (для AI-инструментов, CI/CD, автоматизированных скриптов). **НЕ используйте `cd` в командах** — это относится ко всем способам выполнения.
- Фреймворк для Python-компонентов — `pytest`. Модуль `unittest` не использовать.
- Все тесты размещаются в каталоге `./tests`, сохраняя зеркальную структуру.
- Обязательна аннотация типов и наличие docstring для каждого тестового модуля, класса и функции.
- Тестовые данные и фикстуры должны быть минимальными и описательными. Общие фикстуры выносить в `conftest.py`.
- Корневой `conftest.py` размещается в каталоге `tests/` и содержит фикстуры/фабрики, используемые несколькими модулями; в подпакетах допускаются дополнительные `conftest.py` для доменных сценариев.
- Для мокирования использовать `pytest-mock` (`MockerFixture`) или стандартные средства `pytest`. Глобальные моки ограничивать сроком жизни теста.
- Локальные настройки и секреты не хранить в тестах. Использовать отдельный конфиг файл.
- Общие фабрики данных размещаются в `tests/factories` (или соседних доменных подпапках) и импортируются в тесты через `conftest.py`, чтобы избежать дублирования.
- Повторно используемые хелперы (API-пути, нормализация времени, запуск клиентов) выносить в отдельные библиотеки (`tests/utils.py`, `tests/factories/`) и подключать через импорт вместо дублирования кода.
- Логи тестов должны быть информативными (см. `LogCaptureFixture`), но не зашумлять вывод CI. Дефолтный уровень логирования для локальных и CI-прогонов — `WARNING`; снижение уровня оформляется в тесте явно. Рекомендуемый формат сообщения — `<module>::<scenario>::<context>`.
- **Запуск тестов**: доступны два способа запуска тестов Python:
  
  **Способ 1: Через uv (рекомендуется)**
  ```bash
  uv run pytest tests/ -v
  ```
  
  **Способ 2: Через активацию виртуального окружения**
  
  Команды выполняются **ОТДЕЛЬНО** (активация и запуск — это две разные команды):
  
  ```bash
  # Команда 1: Активировать виртуальное окружение (ОТДЕЛЬНАЯ команда)
  source .venv/bin/activate  # Linux/Mac
  # или
  .venv\Scripts\activate  # Windows
  
  # Команда 2: Запустить тесты (ОТДЕЛЬНАЯ команда после активации)
  pytest tests/ -v
  ```
  
  **ВАЖНО**: 
  - Рабочая директория уже установлена в корень проекта автоматически (для AI-инструментов, CI/CD, автоматизированных скриптов).
  - Все команды выполняются относительно корня проекта без использования `cd`.
  - **НЕ используйте `cd` в командах** — это относится ко всем способам выполнения (вручную, автоматически, через AI-инструменты, в CI/CD).
  - При использовании способа 2: активация `.venv` и запуск тестов — это **ОТДЕЛЬНЫЕ команды**.
  - После активации используйте команду `pytest` напрямую (не `.venv/bin/python -m pytest`).
  
- Последовательность локального запуска python-тестов:
  1. `uv sync` — установка и актуализация зависимостей (или активация `.venv` через `source .venv/bin/activate`).
  2. `uv run pytest --maxfail=1 --disable-warnings` — базовый прогон (или после активации: `pytest --maxfail=1 --disable-warnings`).
  3. `uv run pytest --cov=backend --cov-report=term-missing` — проверка покрытия перед публикацией (или после активации: `pytest --cov=backend --cov-report=term-missing`).
  
  **Важно**: При использовании активации `.venv` команды активации и запуска тестов должны быть отдельными.
- Те же команды закреплены в GitHub Actions `.github/workflows/ci-python-tests.yml`, `.github/workflows/ci-frontend-tests.yml` и `.github/workflows/ci-android.yml`. При обновлении workflow необходимо синхронизировать документ.
- Общие правила расположения артефактов и документов описаны в `docs/ARTIFACTS_LAYOUT.md`; при добавлении новых тестовых пакетов ссылаться на соответствующие разделы.

## 3. Автоматические тесты клиентских приложений (Android)
- **Инструментарий**: Kotlin + JUnit5/AndroidX Test для модульных и инструментальных тестов. Для сквозных сценариев — Espresso или UI Automator.
- **Структура**:
  - Модульные тесты Kotlin находятся в `android/app/src/test/java`.
  - Инструментальные тесты — в `android/app/src/androidTest/java`.
- **Соглашения**:
  - Именование классов тестов: `<ClassName>Test.kt` или `<FeatureName>Spec.kt`.
  - Каждый тест описывает ожидаемое поведение (`fun someCondition_expectedResult()`).
  - Использовать `MockK` или встроенные фреймворки для изоляции зависимостей.
  - При работе с базой данных и сетевыми слоями применять фейковые реализации или эмуляторы.
  - Для UI-тестов гарантировать стабильные идентификаторы `View` (resource-id/contentDescription).
- **Запуск**: описать команды в `docs/DEVELOPMENT.md` и поддерживать Gradle-задачи (`./gradlew test`, `./gradlew connectedDebugAndroidTest`). Минимальный smoke-набор приведён в таблице «Smoke-наборы Android».
- **Отчётность**: хранить артефакты (JUnit XML, скриншоты) в `android/app/build/reports`. CI вытягивает их после прогона.

### 3.1 Smoke-наборы Android

| Сценарий | Описание | Тип теста |
| --- | --- | --- |
| `Создание задачи` | Создать задачу с напоминанием и убедиться, что приходит уведомление в установленный слот | Инструментальный |
| `Синхронизация и редактирование` | Активировать синхронизацию, изменить параметры задачи и подтвердить обновление статуса | Интеграционный |
| `Настройки напоминаний` | Переключить напоминания в настройках приложения и проверить сохранение состояния | UI/E2E |

## 4. Автоматические тесты веб-клиента
- **Стек**: `vitest` для модульных/юнит-тестов, `playwright` или `cypress` для end-to-end. Предпочтительно `playwright` для единообразия и интеграции с CI.
- **Структура**:
  - Юнит-тесты — `frontend/tests/unit`. Именование файлов: `<module>.spec.js` или `.ts` (при миграции на TypeScript).
  - Интеграционные/компонентные тесты — `frontend/tests/integration`.
  - E2E-скрипты — `frontend/tests/e2e`.
- **Соглашения**:
  - Использовать тестовые util-функции (`frontend/utils`) для подготовки данных.
  - Не обращаться напрямую к реальному backend; использовать мок-сервер (MSW) или Playwright fixtures.
  - Прежде чем фиксировать селекторы, обеспечивать устойчивость: data-testid, aria-label, роль.
  - Покрывать не только happy-path, но и негативные сценарии (ошибки сети, пустые состояния).
- **Запуск**:
  - Юнит: `npm run test` (или аналогичная команда через `uv` при конвертации).
  - E2E: `npx playwright test` с настройкой CI-профиля (`playwright.config.ts`). Обязательные сценарии сведены в таблицу «Smoke-наборы веб-клиента» и выполняются на каждый merge request.
- **Отчётность**: сохранять отчёты в `frontend/tests/reports`. CI публикует HTML-репорты и прикладывает скриншоты/видео.

## 5. Интеграция с CI/CD

### 4.1 Smoke-наборы веб-клиента

| Сценарий | Описание | Тип теста |
| --- | --- | --- |
| `Авторизация` | Выполнить вход под тестовым пользователем и проверить редирект на список задач | E2E |
| `Создание задачи` | Создать задачу и убедиться, что она отображается в списке с корректным расписанием | E2E |
| `Редактирование расписания` | Изменить расписание задачи и проверить обновление календаря/виджета | Интеграционный |
| `Удаление задачи` | Удалить задачу и проверить корректное отображение пустого состояния | E2E |
- Все тестовые цепочки должны запускаться в CI при каждом push/PR: backend pytest, Android юнит-тесты, веб-юнит и E2E (в nightly или по тегу).
- Невыеявленные флаки должны помечаться и отслеживаться отдельно. Флаки разрешается временно пропускать только по решению владельца проекта.
- Метрики покрытия (coverage) публикуются в job-артефактах: HTML-отчёт помещается в артефакт `coverage-report`, XML (`coverage.xml`) — в `coverage-summary` для интеграции с Codecov. Для python-домена также выгружается `coverage.lcov` в артефакт `coverage-lcov` и загружается в Codecov. Порог покрытия: не ниже 80% для критичных модулей.
- Для тяжёлых E2E допускается nightly-запуск, но smoke-набор (минимум 3 ключевых сценария) должен выполняться на каждый merge request.

## 6. Документация и поддержка
- Любые новые тестовые сценарии сопровождаются записью в `CHANGELOG_HISTORY.md` при значимых изменениях.
- Руководство по локальному запуску тестов обновляется в `docs/DEVELOPMENT.md`.
- Ответственный за тестирование компонент фиксируется в задаче/issue. Важно поддерживать актуальность контактов.
- В случае обнаружения дефектов тестового окружения — фиксировать в баг-трекере с шагами воспроизведения и ссылкой на failing test.

## 7. Порядок внедрения
- Этап 1: согласовать стек инструментов (Playwright/Cypress, MockK и т. п.) и описать команды запуска.
- Этап 2: покрыть smoke-сценарии веб-клиента и критичные бизнес-операции в Android.
- Этап 3: расширять покрытия, внедрять проверки в CI, отслеживать флаки.
- Этап 4: поддерживать регресс-набор к релизам, формировать отчёты и ретроспективы по качеству.

---
Документ подлежит регулярному пересмотру по мере развития продукта и инфраструктуры тестирования.

